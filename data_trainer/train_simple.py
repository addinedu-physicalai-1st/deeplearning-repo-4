
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

# --- ê²½ë¡œ ì„¤ì • ---
# ê¸°ì¡´ legacy ë°ì´í„° í´ë” ì‚¬ìš©
DATA_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'data_collector', 'data', 'legacy'))
MODELS_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), 'models'))
SAVE_PATH = os.path.join(MODELS_DIR, 'simple_lstm.h5')

# --- í•˜ì´í¼íŒŒë¼ë¯¸í„° ---
SEQUENCE_LENGTH = 45
LANDMARKS_COUNT = 21
COORDS_COUNT = 3
INPUT_SHAPE = (SEQUENCE_LENGTH, LANDMARKS_COUNT * COORDS_COUNT)
EPOCHS = 50
BATCH_SIZE = 16

def normalize_landmarks(data):
    """
    ëœë“œë§ˆí¬ ì •ê·œí™”: (Frames, 21, 3) -> ì†ëª© ê¸°ì¤€ ìƒëŒ€ ì¢Œí‘œ
    """
    wrist = data[:, 0:1, :]
    normalized = data - wrist
    # ê°„ë‹¨í•œ ìŠ¤ì¼€ì¼ë§
    scale = np.max(np.abs(normalized), axis=(1, 2), keepdims=True) + 1e-6
    normalized = normalized / scale
    return normalized

def load_data(data_dir):
    X = []
    y = []
    label_map = {}
    current_label_id = 0
    count_per_class = {}

    if not os.path.exists(data_dir):
        print(f"ì˜¤ë¥˜: ë°ì´í„° í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_dir}")
        return np.array(X), np.array(y), label_map

    # Gesture ë° Posture í´ë” íƒìƒ‰
    modes = ['Gesture', 'Posture']
    
    for mode in modes:
        mode_path = os.path.join(data_dir, mode)
        if not os.path.exists(mode_path):
            continue
            
        gestures = sorted(os.listdir(mode_path))
        for gesture in gestures:
            gesture_path = os.path.join(mode_path, gesture)
            if not os.path.isdir(gesture_path):
                continue
                
            if gesture not in label_map:
                label_map[gesture] = current_label_id
                count_per_class[gesture] = 0
                current_label_id += 1
            
            label_id = label_map[gesture]
            
            # .npy íŒŒì¼ ë¡œë“œ
            for file in os.listdir(gesture_path):
                if file.endswith('.npy'):
                    file_path = os.path.join(gesture_path, file)
                    try:
                        data = np.load(file_path)
                        
                        # ì „ì²˜ë¦¬
                        data = normalize_landmarks(data)
                        
                        # ì‹œí€€ìŠ¤ ê¸¸ì´ ë§ì¶”ê¸°
                        if data.shape[0] > SEQUENCE_LENGTH:
                            data = data[:SEQUENCE_LENGTH]
                        elif data.shape[0] < SEQUENCE_LENGTH:
                            padding = np.zeros((SEQUENCE_LENGTH - data.shape[0], 21, 3))
                            data = np.vstack((data, padding))
                        
                        # í‰íƒ„í™” (45, 21, 3) -> (45, 63)
                        data_flat = data.reshape(SEQUENCE_LENGTH, -1)
                        
                        X.append(data_flat)
                        y.append(label_id)
                        count_per_class[gesture] += 1
                        
                    except Exception as e:
                        print(f"Error loading {file}: {e}")

    # ë°ì´í„° ê°œìˆ˜ ì¶œë ¥
    print("\n" + "="*40)
    print("ğŸ“Š í•™ìŠµ ë°ì´í„° í†µê³„")
    print("="*40)
    total_count = 0
    for gesture, count in count_per_class.items():
        print(f" - {gesture}: {count} ê°œ")
        total_count += count
    print("-" * 40)
    print(f" ì´ ë°ì´í„° ê°œìˆ˜: {total_count} ê°œ")
    print("="*40 + "\n")

    return np.array(X), np.array(y), label_map

def create_simple_model(num_classes):
    """
    í•„ìˆ˜ ê¸°ëŠ¥ë§Œ í¬í•¨í•œ ì‹¬í”Œ LSTM ëª¨ë¸
    """
    model = Sequential([
        LSTM(64, return_sequences=True, input_shape=INPUT_SHAPE),
        LSTM(32, return_sequences=False),
        Dense(32, activation='relu'),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

def main():
    os.makedirs(MODELS_DIR, exist_ok=True)
    
    print("ë°ì´í„° ë¡œë”© ì¤‘...")
    X, y, label_map = load_data(DATA_DIR)
    
    if len(X) == 0:
        print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. collect_mp_legacy.pyë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë¨¼ì € ìˆ˜ì§‘í•˜ì„¸ìš”.")
        return

    # One-hot encoding
    num_classes = len(label_map)
    y_encoded = to_categorical(y, num_classes=num_classes)
    
    # Split
    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)
    
    print(f"í•™ìŠµ ë°ì´í„°: {X_train.shape}, ê²€ì¦ ë°ì´í„°: {X_test.shape}")
    
    # Model
    model = create_simple_model(num_classes)
    model.summary()
    
    print("\ní•™ìŠµ ì‹œì‘...")
    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test))
    
    # Save
    model.save(SAVE_PATH)
    print(f"\nâœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {SAVE_PATH}")

if __name__ == "__main__":
    main()
