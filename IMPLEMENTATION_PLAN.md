# Gesto 1주일 구현 계획

## 프로젝트 현황

- 현재 상태: 초기 단계 (README, 규칙 파일만 존재)
- 목표: 웹캠과 제스처로 PPT와 유투브를 제어하는 핸즈프리 발표 도구 완성
- 기술 스택: Mediapipe, LSTM, PyAutoGui, PyQT6, Python 3.10

## 일정 개요

### 1일차: 프로젝트 구조 및 개발 환경 구축

**목표**: 개발 환경 설정 및 기본 프로젝트 구조 생성

**작업 내용**:

- [ ] conda 가상환경 생성 및 활성화
- [ ] `requirements.txt` 작성 (Mediapipe, PyAutoGui, PyQT6, TensorFlow/Keras, numpy, opencv-python 등)
- [ ] 프로젝트 디렉토리 구조 생성:
  ```
  gesto/
  ├── src/
  │   ├── gesture/        # 제스처 인식 모듈
  │   ├── control/        # 제어 로직 모듈
  │   ├── ui/             # PyQT6 UI 모듈
  │   └── utils/          # 유틸리티 함수
  ├── models/             # 학습된 LSTM 모델
  ├── data/               # 학습 데이터
  ├── assets/             # 이미지 및 리소스
  ├── tests/              # 테스트 코드
  ├── main.py             # 메인 실행 파일
  └── requirements.txt
  ```

- [ ] 기본 설정 파일 생성 (config.py)
- [ ] `.gitignore` 업데이트 (Python, 모델 파일, 데이터 파일 등)

**산출물**:

- 프로젝트 구조
- requirements.txt
- 기본 설정 파일

---

### 2일차: PyQT6 UI 기본 구조 구현

**목표**: UI 스켈레톤 구현 및 레이아웃 설계

**작업 내용**:

- [ ] `src/ui/main_window.py` 구현
  - [ ] 메인 윈도우 클래스 생성
  - [ ] 기본 레이아웃 설계 (QHBoxLayout, QVBoxLayout)
  - [ ] 웹캠 영상 표시 영역 (QLabel 또는 QGraphicsView) - 더미 이미지로 초기화
  - [ ] 제스처 인식 상태 표시 영역 (QLabel)
  - [ ] 모드 선택 버튼 (PPT/유투브) - QRadioButton 또는 QPushButton
  - [ ] 시작/종료 버튼 (QPushButton) - 클릭 이벤트 핸들러 (더미 함수)
  - [ ] **감도 설정 슬라이드 (QSlider)** - 제스처 인식 민감도 조절 (0-100%)
  - [ ] 감도 값 표시 레이블 (QLabel)
  - [ ] 상태바 (QStatusBar)
- [ ] `src/ui/gesture_display.py` 구현 (기본 구조)
  - [ ] 제스처 표시 위젯 클래스
  - [ ] 레이아웃 준비
- [ ] `main.py` 구현
  - [ ] PyQT6 애플리케이션 초기화
  - [ ] 메인 윈도우 표시
  - [ ] 이벤트 루프 실행

**산출물**:

- PyQT6 UI 스켈레톤
- 기본 레이아웃 및 버튼
- 실행 가능한 UI 애플리케이션

---

### 3일차: 공통 기능 구현 - Mediapipe 기반 손 랜드마크 추출

**목표**: 공통 필수 기능인 동작 감지 시작/종료를 위한 기본 제스처 인식 구현

**작업 내용**:

- [ ] `src/utils/camera.py` 구현
  - [ ] 웹캠 초기화 및 관리
  - [ ] 프레임 캡처 및 전처리
  - [ ] 에러 처리 (웹캠 접근 실패 등)
- [ ] `src/gesture/mediapipe_handler.py` 구현
  - [ ] Mediapipe Hands 솔루션 초기화
  - [ ] 실시간 손 랜드마크 추출
  - [ ] 랜드마크 데이터 전처리 (정규화)
- [ ] `src/gesture/gesture_detector.py` 구현 (기본 버전)
  - [ ] 간단한 제스처 인식 로직 (예: 주먹/펴기 기반 시작/종료)
  - [ ] **감도 기반 제스처 인식 로직 구현**
    - [ ] 감도 값에 따라 인식 임계값 조절
    - [ ] 낮은 감도: 더 엄격한 조건 (정확한 제스처만 인식)
    - [ ] 높은 감도: 더 관대한 조건 (유사한 제스처도 인식)
  - [ ] 제스처 상태 관리 (시작/종료)
  - [ ] 제스처 인식 결과 반환
- [ ] 기본 테스트 스크립트 작성

**산출물**:

- 웹캠 관리 유틸리티
- Mediapipe 기반 손 랜드마크 추출 모듈
- 기본 제스처 인식 모듈 (공통 기능용)

---

### 4일차: 공통 기능을 UI에 연결

**목표**: 동작 감지 시작/종료 기능을 UI에 통합

**작업 내용**:

- [ ] `src/ui/main_window.py` 업데이트
  - [ ] 웹캠 영상 실시간 표시 (OpenCV 프레임을 QPixmap으로 변환)
  - [ ] 시작 버튼 클릭 시:
    - [ ] 웹캠 초기화
    - [ ] Mediapipe 핸들러 시작
    - [ ] 제스처 인식 루프 시작 (QTimer 사용)
    - [ ] 상태 표시 업데이트
  - [ ] 종료 버튼 클릭 시:
    - [ ] 웹캠 해제
    - [ ] 제스처 인식 중지
    - [ ] 리소스 정리
    - [ ] 상태 표시 업데이트
  - [ ] **감도 슬라이드 이벤트 연결**
    - [ ] 슬라이드 값 변경 시 제스처 인식 모듈에 감도 전달
    - [ ] 실시간 감도 값 표시 업데이트
    - [ ] 감도 변경에 따른 제스처 인식 동작 즉시 반영
- [ ] `src/ui/gesture_display.py` 업데이트
  - [ ] 실시간 손 랜드마크 시각화 (Mediapipe 결과를 화면에 그리기)
  - [ ] 인식된 제스처 표시
  - [ ] 상태 표시 (감지 중/중지됨)
- [ ] 이벤트 시그널/슬롯 연결
- [ ] 에러 처리 및 사용자 피드백

**산출물**:

- UI와 제스처 인식 모듈 통합
- 동작 감지 시작/종료 기능 완성
- 실시간 웹캠 영상 표시

---

### 5일차: LSTM 모델 및 고급 제스처 인식 구현

**목표**: 다양한 제스처를 인식하기 위한 LSTM 모델 구현

**작업 내용**:

- [ ] `src/gesture/lstm_model.py` 구현
  - [ ] LSTM 모델 아키텍처 설계 (입력: 시퀀스 랜드마크, 출력: 제스처 클래스)
  - [ ] 모델 컴파일 및 학습 함수
  - [ ] 모델 저장/로드 함수
- [ ] `src/gesture/data_collector.py` 구현
  - [ ] 제스처 데이터 수집 도구
  - [ ] 각 제스처별 데이터 수집 (시퀀스 저장)
  - [ ] 데이터 라벨링 시스템
- [ ] 제스처 정의 및 클래스 매핑
  - [ ] 공통: 시작, 종료
  - [ ] PPT: 다음, 이전, 쇼 시작
  - [ ] 유투브: 재생, 일시정지, 볼륨업, 볼륨다운, 음소거, 전체화면
- [ ] `src/gesture/gesture_detector.py` 업데이트
  - [ ] LSTM 모델 통합
  - [ ] 시퀀스 데이터 수집 및 예측
  - [ ] **감도 기반 제스처 분류 로직**
    - [ ] LSTM 예측 확률에 감도 값 적용
    - [ ] 감도에 따른 인식 임계값 동적 조절
    - [ ] 낮은 감도: 높은 확률 요구, 높은 감도: 낮은 확률로도 인식
  - [ ] 제스처 분류 로직
- [ ] 초기 학습 데이터 수집 (각 제스처당 최소 50-100개 샘플)

**산출물**:

- LSTM 모델 구조
- 데이터 수집 도구
- 고급 제스처 인식 모듈
- 초기 학습 데이터셋

---

### 6일차: PPT/유투브 제어 기능 구현 및 UI 연결

**목표**: 제스처 인식 결과에 따른 화면 제어 기능 구현 및 UI 통합

**작업 내용**:

- [ ] `src/control/ppt_controller.py` 구현
  - [ ] 다음 슬라이드: `pyautogui.press('right')` 또는 `pyautogui.hotkey('ctrl', 'right')`
  - [ ] 이전 슬라이드: `pyautogui.press('left')` 또는 `pyautogui.hotkey('ctrl', 'left')`
  - [ ] 슬라이드 쇼 시작: `pyautogui.hotkey('f5')` 또는 PowerPoint 자동화
- [ ] `src/control/youtube_controller.py` 구현
  - [ ] 재생/일시정지: `pyautogui.press('space')`
  - [ ] 볼륨업: `pyautogui.press('up')` (여러 번)
  - [ ] 볼륨다운: `pyautogui.press('down')` (여러 번)
  - [ ] 음소거: `pyautogui.press('m')`
  - [ ] 전체화면: `pyautogui.press('f')`
- [ ] `src/control/controller_manager.py` 구현
  - [ ] 모드 전환 (PPT/유투브)
  - [ ] 제스처-액션 매핑 관리
  - [ ] 제어 명령 실행
- [ ] `src/ui/main_window.py` 업데이트
  - [ ] 모드 선택 버튼 기능 연결
  - [ ] 제스처 인식 결과를 제어 로직에 전달
  - [ ] 제어 액션 실행 피드백 표시
  - [ ] **감도 슬라이드와 제어 기능 연동 확인**
- [ ] 통합 테스트
  - [ ] 각 모드별 제스처 인식 및 제어 동작 확인
  - [ ] 감도 변경에 따른 제스처 인식 변화 테스트

**산출물**:

- PPT 제어 모듈
- 유투브 제어 모듈
- 제어 관리자
- UI와 제어 로직 통합
- 완전한 기능을 가진 애플리케이션

---

### 7일차: 통합 테스트, 버그 수정 및 최적화

**목표**: 전체 시스템 통합 테스트 및 최종 완성

**작업 내용**:

- [ ] 통합 테스트
  - [ ] 전체 플로우 테스트 (시작 → 제스처 인식 → 제어 → 종료)
  - [ ] PPT 모드 전체 플로우 테스트
  - [ ] 유투브 모드 전체 플로우 테스트
  - [ ] 모드 전환 테스트
  - [ ] 에러 케이스 테스트
- [ ] 제스처 인식 정확도 테스트
  - [ ] 각 제스처별 인식률 측정
  - [ ] 오인식 케이스 분석
  - [ ] **감도별 인식 정확도 테스트**
    - [ ] 낮은 감도에서의 정확도
    - [ ] 높은 감도에서의 인식률
    - [ ] 최적 감도 값 찾기
- [ ] 버그 수정
  - [ ] 발견된 버그 수정
  - [ ] 엣지 케이스 처리
- [ ] 성능 최적화
  - [ ] 프레임 처리 속도 개선
  - [ ] 메모리 사용량 최적화
  - [ ] 제스처 인식 지연 최소화
- [ ] 에러 처리 강화
  - [ ] 예외 상황 처리
  - [ ] 로깅 시스템 추가
- [ ] 사용성 개선
  - [ ] UI/UX 개선
  - [ ] 피드백 메시지 추가
  - [ ] 사용자 가이드 작성
  - [ ] **감도 설정 사용법 가이드 추가**
- [ ] 최종 테스트 및 문서화
  - [ ] README 업데이트 (사용법, 설치 방법)
  - [ ] 주요 기능 데모 준비

**산출물**:

- 최종 완성된 애플리케이션
- 테스트 결과 리포트
- 업데이트된 문서
- 데모 준비

